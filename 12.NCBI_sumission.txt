# Submiting assembled genomes - NCBI Genome DB - BioProject PRJNA1042624 
# -------------------------------------------------------------------------
# Filtering contigs with less than 200 nt
## Install and load the Biostrings package if not already installed
if (!requireNamespace("Biostrings", quietly = TRUE)) {
  install.packages("Biostrings")
}
library(Biostrings)

## Set the working directory to the location of your scaffold FASTA files
setwd("/home/joao/Documents/IC3/Collaborations/Mangrove_Microbiota/WGS/all_scaffolds")

## List all the scaffold FASTA files
fasta_files <- list.files(pattern = "\\.fasta$", full.names = TRUE)

## Function to filter sequences shorter than 500 nucleotides
filter_short_sequences <- function(file_path) {
  # Read the sequences from the FASTA file
  sequences <- readDNAStringSet(file_path)
  
  # Filter sequences shorter than 500 nucleotides
  long_sequences <- sequences[nchar(sequences) >= 500]
  
  # Write the filtered sequences to a new FASTA file
  writeXStringSet(long_sequences, file = paste0(tools::file_path_sans_ext(file_path), "_filtered.fasta"))
}

## Apply the function to each FASTA file
lapply(fasta_files, filter_short_sequences)
 

# Removing contaminations identified by NCBI 
# -------------------------------------------------------------------------
# Removing contaminations using FCS (Foreign Contamination Screening)-adaptor tool from NCBI
## Creating directories to install tool
mkdir fcsadaptor
cd fcsadaptor
curl -LO https://github.com/ncbi/fcs/raw/main/dist/run_fcsadaptor.sh # Get a copy of the run script
chmod 755 run_fcsadaptor.sh # Change the permissions of run_fcsadaptor.sh
mkdir inputdir outputdir # Create input and output directories; move all fasta files inside inputdir

cd ~/Documents/IC3/Collaborations/Mangrove_Microbiota/WGS/NCBI_submission/fcsadaptor

## Get singularity working 
conda create --name singularity
conda activate singularity
 conda install conda-forge::singularity
 
## Iterating over every fasta file and running the tool 
curl https://ftp.ncbi.nlm.nih.gov/genomes/TOOLS/FCS/releases/latest/fcs-adaptor.sif -Lo fcs-adaptor.sif # Download the Singularity image

for file in inputdir/*.fasta; do
    filename=$(basename "$file")  # Extract the filename
    filename_no_ext="${filename%.fasta}"  # Remove the file extension
    mkdir -p "outputdir/$filename_no_ext" # Create the output directory for this file

    ./run_fcsadaptor.sh --fasta-input "$file" --output-dir "outputdir/$filename_no_ext" --prok --container-engine singularity --image fcs-adaptor.sif # Run the FCS adaptor tool on this FASTA file using Singularity
done # if the genomes are eukaryotic use --euk

### ----------------------------------- ALTERNATIVE: do it manually 
## Download all contaminations reports from NCBI and move them to a specified folder

## Trimming contamination reports 
for file in ./Contamination*; do
    tail -n 3 "$file" > "${file}.temp"
    mv "${file}.temp" "$file"
done

mkdir filtered_scaffolds
mv *_filtered.fasta filtered_scaffolds/
mv all_scaffolds/filtered_scaffolds NCBI_submission/

## Removing contaminations 
### For SA1
contamination_line=$(grep -n "NODE_49" filtered_scaffolds/SA1_scaffold_filtered.fasta | cut -d ":" -f 1)
next_line=$((contamination_line + 1)) # Identify the line numbers containing the contamination and the line below it
sed -e "${contamination_line},${next_line}d" filtered_scaffolds/SA1_scaffold_filtered.fasta > cleaned_SA1_scaffold_filtered.fasta # Exclude contamination 
grep NODE_49 cleaned_SA1_scaffold_filtered.fasta # checking if it worked

### For the remaining isolates
contamination_line=$(grep -n "NODE_47" filtered_scaffolds/SB1_scaffold_filtered.fasta | cut -d ":" -f 1)
next_line=$((contamination_line + 1)) 
sed -e "${contamination_line},${next_line}d" filtered_scaffolds/SB1_scaffold_filtered.fasta > cleaned_SB1_scaffold_filtered.fasta 
grep NODE_47 cleaned_SB1_scaffold_filtered.fasta 

contamination_line=$(grep -n "NODE_26_length_5051_cov_287.398874" filtered_scaffolds/SB8_scaffold_filtered.fasta | cut -d ":" -f 1)
next_line=$((contamination_line + 1)) 
sed -e "${contamination_line},${next_line}d" filtered_scaffolds/SB8_scaffold_filtered.fasta > cleaned_SB8_scaffold_filtered.fasta 
grep NODE_26_length_5051_cov_287.398874 cleaned_SB8_scaffold_filtered.fasta 

contamination_line=$(grep -n "NODE_65_length_416_cov_233.578171" filtered_scaffolds/WB3_scaffold_filtered.fasta | cut -d ":" -f 1)
next_line=$((contamination_line + 1)) 
sed -e "${contamination_line},${next_line}d" filtered_scaffolds/WB3_scaffold_filtered.fasta > cleaned_WB3_scaffold_filtered.fasta 
grep NODE_65_length_416_cov_233.578171 cleaned_WB3_scaffold_filtered.fasta 

contamination_line=$(grep -n "NODE_22_length_2705_cov_188.989726" filtered_scaffolds/WB8II_scaffold_filtered.fasta | cut -d ":" -f 1)
next_line=$((contamination_line + 1)) 
sed -e "${contamination_line},${next_line}d" filtered_scaffolds/WB8II_scaffold_filtered.fasta > cleaned_WB8II_scaffold_filtered.fasta 
grep NODE_22_length_2705_cov_188.989726 cleaned_WB8II_scaffold_filtered.fasta 

### Renaming them so I can submit them again in NCBI
rename 's/cleaned_//' cleaned_*
mv *.fasta filtered_scaffolds




 

















